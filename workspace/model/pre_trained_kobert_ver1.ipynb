{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "47d1f644",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "import MeCab\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "fe4c0b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 메모리 최적화\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "21c5ad05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 로드\n",
    "path = '~/aiffel/dktc/data_forder/result.csv'\n",
    "data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "510c1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MeCab 형태소 분석기 초기화\n",
    "mecab = MeCab.Tagger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "f3e108a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MeCab의 parse 결과를 파싱하여 (word, pos) 튜플의 리스트로 변환하는 함수\n",
    "def parse_mecab_output(text):\n",
    "    parsed = mecab.parse(text)\n",
    "    parsed_lines = parsed.strip().split('\\n')\n",
    "    tokens = []\n",
    "    for line in parsed_lines:\n",
    "        if line == 'EOS':\n",
    "            break\n",
    "        else:\n",
    "            try:\n",
    "                surface, feature = line.split('\\t')\n",
    "                pos = feature.split(',')[0]\n",
    "                tokens.append((surface, pos))\n",
    "            except ValueError:\n",
    "                continue  # 빈 줄이나 형식에 맞지 않는 줄은 무시\n",
    "    return tokens\n",
    "\n",
    "# 추가된 전처리 함수들\n",
    "def remove_urls_emails(text):\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "093d0783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 및 형태소 분석 클래스 정의\n",
    "class TextPreprocessor:\n",
    "    def __init__(self, pos_to_keep=None):\n",
    "        if pos_to_keep is None:\n",
    "            self.pos_to_keep = [\n",
    "                'NNG', 'NNP', 'NNB', 'NNBC', 'NR', 'NP', 'VV', 'VA', 'VX',\n",
    "                'VCP', 'VCN', 'MM', 'MAG', 'MAJ', 'XR', 'IC', 'JKS', 'JKC',\n",
    "                'JKG', 'JKO', 'JKB', 'JKV', 'JKQ', 'JX', 'JC', 'EP', 'EF',\n",
    "                'EC', 'ETN', 'ETM', 'XPN', 'XSN', 'XSV', 'XSA', 'SN', 'SL',\n",
    "                'SH', 'SY'\n",
    "            ]\n",
    "        else:\n",
    "            self.pos_to_keep = pos_to_keep\n",
    "\n",
    "    def normalize_text(self, text):\n",
    "        text = remove_urls_emails(text)\n",
    "        text = re.sub(r'(.)\\1{2,}', r'\\1\\1', text)  # 반복 문자 줄이기\n",
    "        text = re.sub(r'\\s+', ' ', text)             # 다중 공백 제거\n",
    "        text = text.strip()                          # 앞뒤 공백 제거\n",
    "        return text\n",
    "\n",
    "    def filter_by_pos(self, sentence):\n",
    "        parsed_sentence = parse_mecab_output(sentence)\n",
    "        filtered_tokens = [word for word, pos in parsed_sentence if pos in self.pos_to_keep]\n",
    "        return filtered_tokens\n",
    "\n",
    "    def preprocess_and_tokenize(self, sentence):\n",
    "        if pd.isnull(sentence):\n",
    "            return []\n",
    "        sentence = self.normalize_text(sentence)\n",
    "        tokens = self.filter_by_pos(sentence)\n",
    "        return tokens\n",
    "\n",
    "    def apply_to_dataframe(self, df, column_name):\n",
    "        df[column_name] = df['conversation'].apply(self.preprocess_and_tokenize)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "4aa4558d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 클래스 인스턴스 생성\n",
    "preprocessor = TextPreprocessor()\n",
    "\n",
    "# 데이터프레임 복사\n",
    "df = data.copy()\n",
    "\n",
    "# 전처리 및 토큰화 적용\n",
    "df = preprocessor.apply_to_dataframe(df, 'preprocess_conversation')\n",
    "\n",
    "# 토큰 리스트를 문자열로 변환하여 'processed_text' 컬럼 생성\n",
    "df['processed_text'] = df['preprocess_conversation'].apply(lambda tokens: ' '.join(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "acfbaaac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 인코딩\n",
    "label_encoding = {\n",
    "    '협박 대화': 0,\n",
    "    '기타 괴롭힘 대화': 1,\n",
    "    '갈취 대화': 2,\n",
    "    '직장 내 괴롭힘 대화': 3,\n",
    "    '일반 대화' : 4\n",
    "}\n",
    "df['class'] = df['class'].map(label_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "fac32879",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at kykim/bert-kor-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertModel\n",
    "\n",
    "# 사전 훈련된 한국어 BERT 모델과 토크나이저 로드\n",
    "tokenizer = BertTokenizer.from_pretrained('kykim/bert-kor-base')\n",
    "bert_model = TFBertModel.from_pretrained('kykim/bert-kor-base')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "007eef90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 시퀀스 길이 박스플롯을 위해 패딩 전에 시퀀스 길이 계산\n",
    "sequence_lengths = df['preprocess_conversation'].apply(len).tolist()\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.boxplot(sequence_lengths, vert=False)\n",
    "plt.title('Boxplot of Sequence Lengths')\n",
    "plt.xlabel('Sequence Length')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "13b00b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 함수 정의 (패딩 전에 시퀀스 길이 확인 완료)\n",
    "def tokenize_texts(texts, tokenizer, max_length):\n",
    "    return tokenizer(\n",
    "        texts.tolist(),\n",
    "        padding='max_length',  # 시퀀스를 max_length로 패딩\n",
    "        truncation=True,       # max_length를 초과하는 시퀀스는 자름\n",
    "        max_length=max_length,\n",
    "        return_tensors='tf'    # 텐서 형식으로 반환\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "1ea82aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 시퀀스 길이 결정\n",
    "max_seq_len = 200  # 메모리 부족 문제 해결을 위해 시퀀스 길이 줄이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "4504b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화 수행: 'processed_text' 컬럼 사용\n",
    "tokenized_data = tokenize_texts(df['processed_text'], tokenizer, max_seq_len)\n",
    "\n",
    "input_ids = tokenized_data['input_ids']\n",
    "attention_mask = tokenized_data['attention_mask']\n",
    "\n",
    "# 레이블 준비\n",
    "y = df['class'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "873c448c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터 생성: 클래스별로 200개씩 랜덤 샘플링\n",
    "df_val = df.groupby('class', group_keys=False).apply(lambda x: x.sample(200, random_state=42))\n",
    "df_train = df.drop(df_val.index)\n",
    "\n",
    "# 인덱스 추출\n",
    "train_indices = df_train.index\n",
    "val_indices = df_val.index\n",
    "\n",
    "# 학습 및 검증 데이터 생성\n",
    "X_train_input_ids = input_ids.numpy()[train_indices]\n",
    "X_train_attention_mask = attention_mask.numpy()[train_indices]\n",
    "y_train = y[train_indices]\n",
    "\n",
    "X_val_input_ids = input_ids.numpy()[val_indices]\n",
    "X_val_attention_mask = attention_mask.numpy()[val_indices]\n",
    "y_val = y[val_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d2646866",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dropout, Dense\n",
    "\n",
    "def build_classification_model(max_seq_len, num_classes):\n",
    "    # 입력 레이어 정의\n",
    "    input_ids = Input(shape=(max_seq_len,), dtype=tf.int32, name=\"input_ids\")\n",
    "    attention_mask = Input(shape=(max_seq_len,), dtype=tf.int32, name=\"attention_mask\")\n",
    "    \n",
    "    # BERT 모델을 통해 임베딩 획득\n",
    "    bert_outputs = bert_model(input_ids, attention_mask=attention_mask)\n",
    "    pooled_output = bert_outputs.pooler_output  # [CLS] 토큰의 출력\n",
    "    \n",
    "    # 드롭아웃 레이어\n",
    "    dropout = Dropout(0.3)(pooled_output)\n",
    "    \n",
    "    # 출력 레이어\n",
    "    outputs = Dense(num_classes, activation='softmax')(dropout)\n",
    "    \n",
    "    # 모델 정의\n",
    "    model = Model(inputs=[input_ids, attention_mask], outputs=outputs)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "afa469b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_ids (InputLayer)          [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "attention_mask (InputLayer)     [(None, 200)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "tf_bert_model_5 (TFBertModel)   TFBaseModelOutputWit 118297344   input_ids[0][0]                  \n",
      "                                                                 attention_mask[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_226 (Dropout)           (None, 768)          0           tf_bert_model_5[0][1]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5)            3845        dropout_226[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 118,301,189\n",
      "Trainable params: 118,301,189\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 클래스 수 설정\n",
    "num_classes = 5  # 필요에 따라 조정\n",
    "\n",
    "# 모델 생성\n",
    "model = build_classification_model(max_seq_len, num_classes)\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# 모델 요약 확인\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "d6353cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "import os\n",
    "\n",
    "# 체크포인트 저장 디렉토리 생성\n",
    "checkpoint_dir = 'checkpoints'\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "# 조기 종료 및 모델 체크포인트 콜백 설정\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=3,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "model_checkpoint = ModelCheckpoint(\n",
    "    filepath=os.path.join(checkpoint_dir, 'best_model.h5'),  # 체크포인트 저장 경로\n",
    "    monitor='val_loss',                                      # 모니터링할 지표\n",
    "    save_best_only=True,                                     # 최상의 모델만 저장\n",
    "    save_weights_only=True,                                  # 가중치만 저장\n",
    "    verbose=1                                                # 저장 시 메시지 출력\n",
    ")\n",
    "\n",
    "# 추가적인 학습률 스케줄러 (선택 사항)\n",
    "reduce_lr = ReduceLROnPlateau(\n",
    "    monitor='val_loss',\n",
    "    factor=0.2,\n",
    "    patience=3,\n",
    "    min_lr=1e-6,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# 콜백 리스트에 추가\n",
    "callbacks = [early_stopping, model_checkpoint, reduce_lr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ad21e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "247/247 [==============================] - 197s 740ms/step - loss: 0.5729 - accuracy: 0.7866 - val_loss: 0.2887 - val_accuracy: 0.9060\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.28871, saving model to checkpoints/best_model.h5\n",
      "Epoch 2/10\n",
      "  2/247 [..............................] - ETA: 2:43 - loss: 0.2632 - accuracy: 0.9375"
     ]
    }
   ],
   "source": [
    "# 모델 학습\n",
    "history = model.fit(\n",
    "    [X_train_input_ids, X_train_attention_mask],\n",
    "    y_train,\n",
    "    validation_data=([X_val_input_ids, X_val_attention_mask], y_val),\n",
    "    epochs=10,\n",
    "    batch_size=16, \n",
    "    callbacks=callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b14d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습 과정 시각화\n",
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eb2071a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검증 데이터에 대한 예측 및 분류 보고서\n",
    "y_pred = model.predict([X_val_input_ids, X_val_attention_mask])\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "report = classification_report(y_val, y_pred_classes, target_names=label_mapping.keys(), output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "report_df = report_df[['precision', 'recall', 'f1-score', 'support']]\n",
    "report_df = report_df.round(4)\n",
    "report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da5b8df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# 저장된 모델의 가중치를 불러오는 경로 설정\n",
    "model_path = os.path.join('checkpoints', 'best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a1214e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 매핑 (번호 -> 텍스트)\n",
    "label_mapping = {\n",
    "    0: '협박 대화',\n",
    "    1: '기타 괴롭힘 대화',\n",
    "    2: '갈취 대화',\n",
    "    3: '직장 내 괴롭힘 대화',\n",
    "    4: '일반 대화'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3c41a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 저장된 모델 불러오기\n",
    "model.load_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca09f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. 테스트 데이터 로드\n",
    "test_data_path = '~/aiffel/dktc/data_forder/test.csv'\n",
    "test_df = pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d46fc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. 테스트 데이터 전처리 (훈련 데이터와 동일한 방식으로)\n",
    "test_df['preprocess_conversation'] = test_df['text'].apply(preprocessor.preprocess_and_tokenize)\n",
    "test_df['processed_text'] = test_df['preprocess_conversation'].apply(lambda tokens: ' '.join(tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bc9b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. 토큰화된 테스트 데이터 생성\n",
    "tokenized_test_data = tokenize_texts(test_df['processed_text'], tokenizer, max_seq_len)\n",
    "input_ids_test = tokenized_test_data['input_ids']\n",
    "attention_mask_test = tokenized_test_data['attention_mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bd2397",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. 모델로 예측 수행\n",
    "y_test_pred = model.predict([input_ids_test, attention_mask_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9df27a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. 예측 클래스 추출\n",
    "y_test_pred_classes = np.argmax(y_test_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e101f032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. 예측 클래스 번호를 텍스트 레이블로 변환\n",
    "test_df['class'] = y_test_pred_classes\n",
    "test_df['class'] = test_df['class'].map(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b73d4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. 제출 파일 작성\n",
    "submission = test_df[['idx', 'class']]\n",
    "submission.columns = ['file_name', 'class']\n",
    "submission.to_csv('~/aiffel/dktc/data_forder/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090488a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1ed7e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
